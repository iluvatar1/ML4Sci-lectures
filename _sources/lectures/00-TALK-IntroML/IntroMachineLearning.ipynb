{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# A fast introduction to Machine Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Introduction to Machine Learning\n",
    "\n",
    "> Machine learning is the field of study that gives computers the ability\n",
    "to learn without being explicitly programmed. Arthur Samuel, 1959\n",
    "\n",
    "Learning:\n",
    "> A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E. Tom Mitchellâ€™s, 1997\n",
    " \n",
    "Machine learning is a branch of artificial intelligence that allows computers to learn from given information and perform new but similar tasks. \n",
    "\n",
    "<img src=\"figs/AI-ML.png\" alt=\"transistors-per-microprocessor.png\" width=\"50%\" align=\"center\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Artificial intelligence**: The computer performs actions defined as requiring intelligence -> Moving target\n",
    "- Search Based Heuristic Optimization\n",
    "- Evolutionary computation\n",
    "- Logic Programming (inductive logic programming, fuzzy logic)\n",
    "- robabilistic Reasoning Under Uncertainty (bayesian networks)\n",
    "- Computer Vision\n",
    "- Natural Language Processing\n",
    "- Robotics\n",
    "- Machine Learning\n",
    "\n",
    "Examples:\n",
    "- Self-driving cars\n",
    "- ChatGPT (LLM)\n",
    "- Healthcare: Diagnosis from scans\n",
    "- Finance: Fraud detection\n",
    "- Retail: Recommender systems\n",
    "- Transport: Autonomous vehicles\n",
    "- Creativity: AI art, music, writing\n",
    "\n",
    "\n",
    "<!-- <div style=\"text-align: center;\">\n",
    "    <img src=\"figs/AI-ML.png\" alt=\"Machine learning as a subarea of artificail intelligence. From: Understanding Deep Learning, Simon J.D. Prince\" width=\"600\">\n",
    "    <figcaption>From: Understanding Deep Learning, Simon J.D. Prince</figcaption>\n",
    "</div> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Historical development\n",
    "- https://letsdatascience.com/learn/history/history-of-machine-learning/\n",
    "- https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/2-history-of-ML/README.md\n",
    "- https://www.inveniam.fr/a-brief-history-of-machine-learning\n",
    "- https://ahistoryofai.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Hardware was too costly, but improvements on both cpu and gpu made it practical, or at least attainable, to apply the different AI models.\n",
    "\n",
    "<img src=\"figs/transistors-per-microprocessor.png\" alt=\"transistor versus microprocesos\" width=\"60%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://epochai.org/assets/images/posts/2022/gpu-perf/gpu-perf-banner.png\" alt=\"gpu-perf over time\" style=\"width: 80%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Types of learning\n",
    "<img src=\"./figs/AI-ML.png\" alt=\"ML trends\" width=40% align=\"center\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Practical, short, fast example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Data creation\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "X, y = make_blobs(n_samples=100, centers=2, random_state=42)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr')\n",
    "plt.title(\"Input data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Supervised\n",
    "- Learn from labeled examples\n",
    "- Task: Prediction (classification or regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Train a classifier\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Plot decision boundary\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='bwr')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr')\n",
    "plt.title(\"Supervised Learning: Logistic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Unsupervised \n",
    "- No labels, find structure in data\n",
    "- Task: Clustering or dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "preds = kmeans.predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=preds, cmap='cool')\n",
    "plt.title(\"Unsupervised: K-means Clustering\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Reinforcement learning\n",
    "- Learn by trial and error\n",
    "- Agent interacts with environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src=\"https://www.youtube.com/embed/L_4BPjLBF4E?si=4vNIAkUAz7tkTyiO\", width=\"560\", height=\"315\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Typical workflow\n",
    "<img src=\"./figs/ML-workflow.png\" alt=\"ML workflow\" width=\"50%\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "1. **Dataset Collection**: Depends on the experiment or goals. What kind of data ? (categorical numerical) How much data? Units? reference data? data base? Data storage/access? \n",
    "2. **Dataset preprocessing**: Cleaning data. Missing data. Noise. Outliers. Normalization. Training and test sets. Or Train, validation (for hyper parameters), and test set. \n",
    "3. **Model training**: Depends on the actual approach. For supervised learning we need both input and output values. For unsupervised only input. No underfitting or overfitting. \n",
    "4. **Model evaluation**: Testing the training success, with some defined metrics. Maybe needs to redo some previous steps.\n",
    "\n",
    "### Core concepts\n",
    "- **Data**: examples used for learning\n",
    "- **Features**: inputs (e.g., age, temperature, pixels)\n",
    "- **Model**: function that maps input to output\n",
    "- **Training**: adjusting model to reduce error\n",
    "- **Testing**: evaluate model on new data\n",
    "- **Meta-Parameters**: Parameters controlling the model\n",
    "\n",
    "Beware of under/over fitting : See also last part of <https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "x = np.linspace(0, 6, 30)\n",
    "y = np.sin(x) + 0.3 * np.random.randn(30)\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "# True function\n",
    "x_plot = np.linspace(0, 6, 100).reshape(-1, 1)\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "# Underfitting (degree=1)\n",
    "plt.subplot(1, 3, 1)\n",
    "model_under = make_pipeline(PolynomialFeatures(1), LinearRegression())\n",
    "model_under.fit(X, y)\n",
    "plt.scatter(x, y, label='data')\n",
    "plt.plot(x_plot, np.sin(x_plot), label='true function')\n",
    "plt.plot(x_plot, model_under.predict(x_plot), label='underfit model')\n",
    "plt.title(\"Underfitting\")\n",
    "plt.legend()\n",
    "\n",
    "# Good fit (degree=3)\n",
    "plt.subplot(1, 3, 2)\n",
    "model_good = make_pipeline(PolynomialFeatures(3), LinearRegression())\n",
    "model_good.fit(X, y)\n",
    "plt.scatter(x, y, label='data')\n",
    "plt.plot(x_plot, np.sin(x_plot), label='true function')\n",
    "plt.plot(x_plot, model_good.predict(x_plot), label='good fit')\n",
    "plt.title(\"Good Fit\")\n",
    "plt.legend()\n",
    "\n",
    "# Overfitting (degree=15)\n",
    "plt.subplot(1, 3, 3)\n",
    "model_over = make_pipeline(PolynomialFeatures(15), LinearRegression())\n",
    "model_over.fit(X, y)\n",
    "plt.scatter(x, y, label='data')\n",
    "plt.plot(x_plot, np.sin(x_plot), label='true function')\n",
    "plt.plot(x_plot, model_over.predict(x_plot), label='overfit model')\n",
    "plt.title(\"Overfitting, poor generalization\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## ML Algorithms\n",
    "- https://www.datacamp.com/cheat-sheet/machine-learning-cheat-sheet\n",
    "- https://sites.google.com/view/datascience-cheat-sheets\n",
    "- https://github.com/SamBelkacem/AI-ML-cheatsheets\n",
    "- https://www.naftaliharris.com/blog/visualizing-k-means-clustering/\n",
    "\n",
    "<img src=\"./figs/ML-CheatSheet-01.webp\" alt=\"Some algs ML\" width=\"50%\" align=\"center\">\n",
    "\n",
    "<img src=\"./figs/ML-Cheat-Sheet_2.png\" alt=\"ML cheatsheet\" width=\"50%\" align=\"center\">\n",
    "\n",
    "\n",
    "### Classifier comparison:\n",
    "<https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html>\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_classifier_comparison_001.png\" alt=\"Classifiers\" width=\"80%\" align=\"center\">\n",
    "\n",
    "### Tensor flow playground\n",
    "Try: <https://playground.tensorflow.org>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
