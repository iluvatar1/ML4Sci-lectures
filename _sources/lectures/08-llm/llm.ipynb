{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Large Language Models (LLMs) for Everyone\n",
    "\n",
    "Check: <https://jalammar.github.io/illustrated-transformer/>\n",
    "\n",
    "## A Gentle Welcome to the World of LLMs\n",
    "\n",
    "Imagine a computer that can read, write, explain, and even think like a human — not perfectly, but surprisingly well. That’s what Large Language Models (LLMs) do.\n",
    "\n",
    "They power:\n",
    "\n",
    "- Chatbots like chatgpt, gemini, claude ...\n",
    "- Summarizing research papers\n",
    "- Writing code\n",
    "- Explaining science concepts\n",
    "- Helping scientists discover new materials or drugs\n",
    "\n",
    "But how do they work? \n",
    "\n",
    "> A language model is a computer program that predicts the next word in a sentence. By this simple mechanism, they can even `simulate` reasoning.\n",
    "\n",
    "Example:\n",
    "\n",
    "`\"The cat sat on the ____\"`\n",
    "\n",
    "A language model would guess: \"mat\", \"couch\", \"windowsill\", etc.\n",
    "\n",
    "But it doesn’t just guess — it learns from millions of books, articles, and websites.\n",
    "\n",
    ":::{exercise}\n",
    "Try to predict the next word in each sentence:\n",
    "\n",
    "- \"The sun rises in the...\" → ?\n",
    "- \"Water boils at...\" → ?\n",
    "- \"DNA stands for...\" → ?\n",
    "- \"The E=mc² formula was created by...\" → ?\n",
    "- \"The E=mc² + AI formula was created by...\" → ?\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Building Blocks - How do LLMs work?\n",
    "\n",
    "At their core, LLMs are prediction machines. They predict the next word in a sequence. For example, if you give it the sentence, `\"The cat sat on the...\"`, the LLM will calculate the probabilities of all the words that could come next and choose the most likely one, like `\"mat\"`.\n",
    "\n",
    "This seemingly simple task, when performed on a massive scale, allows LLMs to do amazing things like writing essays, translating languages, and even writing computer code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Transformer: The Engine of LLMs\n",
    "\n",
    "The magic behind modern LLMs lies in a groundbreaking architecture called the **Transformer**. Introduced in a 2017 paper titled \"Attention is All You Need,\" the Transformer revolutionized how we process language. [1] Unlike older models that processed words one by one, the Transformer can look at an entire sentence at once, allowing it to understand the context and relationships between words much more effectively.\n",
    "\n",
    "**Key Components of a Transformer:**\n",
    "\n",
    "*   **Embedding:** First, the text is broken down into smaller units called \"tokens\" (words or parts of words). Each token is then converted into a numerical vector, called an embedding, that captures its meaning.\n",
    "*   **Positional Encoding:** To understand the order of words, the Transformer adds a special vector to each embedding that indicates its position in the sequence.\n",
    "*   **Attention Mechanism:** This is the core innovation of the Transformer. It allows the model to weigh the importance of different words in the input when producing an output. For example, in the sentence, `\"The robot picked up the ball because it was heavy\"`, the attention mechanism helps the model understand that `\"it\"` refers to the `\"ball\"` and not the `\"robot\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: The Attention Mechanism\n",
    "\n",
    "Imagine you're reading a sentence. As you read each word, you're not just looking at that word in isolation. You're constantly making connections to other words in the sentence to understand the overall meaning. The attention mechanism works in a similar way, creating a network of connections between words.\n",
    "\n",
    "![Attention Mechanism Visualization](https://miro.medium.com/v2/resize:fit:1400/1*--_t3_x5Z7L4U2X4Wv2a2w.gif)\n",
    "*A simplified animation showing how attention might work. When processing the word \"it\", the model pays more \"attention\" to \"ball\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM = Large + Language + Model\n",
    "Large: Trained on trillions of words (more than all books in the world!)\n",
    "\n",
    "Language: Understands human language (English, Spanish, code, etc.)\n",
    "\n",
    "Model: A mathematical system that makes predictions\n",
    "\n",
    "| Model | Parameters (Trillions) | Approx. Training Data |\n",
    "|------|------------------------|------------------------|\n",
    "| GPT-3 | 175 | 300 billion words |\n",
    "| Llama 3 | 80 | 10 trillion+ words |\n",
    "| GPT-4 | ~1.8 (estimated) | Massive (not public) |\n",
    "\n",
    "**Parameters** = \"memory cells\" that store what the model learned.\n",
    "\n",
    "More parameters → more knowledge → better predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Cutting Edge - What's New with LLMs?\n",
    "\n",
    "The field of LLMs is moving at an incredible pace. Here are two of the most exciting recent developments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixture of Experts (MoE): The Power of Specialization\n",
    "\n",
    "Imagine a team of experts. Instead of one person trying to know everything, you have specialists for different topics. A Mixture of Experts (MoE) model works on a similar principle. It's a neural network architecture that has multiple \"expert\" sub-networks, each specializing in different parts of the input data. [2]\n",
    "\n",
    "A \"gating network\" decides which expert (or combination of experts) is best suited to handle a particular input. This makes the model much more efficient, as only a fraction of the model is used for any given task. This allows for the creation of much larger and more powerful models without a massive increase in computational cost.\n",
    "\n",
    "#### Visualization: Mixture of Experts\n",
    "\n",
    "Think of a large company with different departments (experts) like marketing, finance, and engineering. When a new project comes in, the manager (gating network) directs it to the most relevant department.\n",
    "\n",
    "![MoE Diagram](https://huggingface.co/blog/assets/moe/moe.png)\n",
    "*Image from Hugging Face, showing how an input token is routed by the gating network to specific experts.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasoning: Can LLMs \"Think\"?\n",
    "\n",
    "A major area of research is improving the reasoning abilities of LLMs. While they are excellent at recognizing patterns in data, they can struggle with tasks that require genuine logical deduction. Researchers are developing techniques to train LLMs to perform multi-step reasoning, which improves their performance on tasks like math problems and programming.\n",
    "\n",
    "However, it's important to note that the extent of their reasoning abilities is still a topic of debate. Some studies suggest that what appears to be reasoning might actually be a sophisticated form of pattern matching based on their training data. Recent research has shown that while these models can generate detailed \"thinking processes,\" their accuracy can drop significantly as problems become more complex. \n",
    "\n",
    "#### Self-Consistency & Verification\n",
    "New models don’t just give one answer — they check their work.\n",
    "\n",
    "They generate multiple possible answers\n",
    "Then pick the most consistent one\n",
    "Example:\n",
    "\"What is the pH of pure water?\"\n",
    "\n",
    "- Model says: \"7\"\n",
    "- It checks: \"Yes, neutral, matches known science\"\n",
    "- Confidence: High\n",
    "This is crucial for scientific accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Simple Exercise 2: Testing Reasoning**\n",
    "\n",
    "Try giving an LLM a simple logic puzzle. You can use an online LLM interface for this.\n",
    "\n",
    "> **Prompt:** \"If a plane crashes on the border between the United States and Canada, where do they bury the survivors?\"\n",
    "\n",
    "An LLM with good reasoning abilities should be able to identify the trick in the question (you don't bury survivors). This can be a fun way to see how these models handle a bit of wordplay and logic. Note down its response. Does it get it right? How does it explain its answer?\n",
    "\n",
    "Another example: \"If a car travels 60 km/h for 2 hours, how far does it go?\"\n",
    "\n",
    "Old way: \"120 km\" (guess)\n",
    "\n",
    "New way (Chain-of-Thought):\n",
    "- Step 1: Speed = 60 km/h\n",
    "- Step 2: Time = 2 hours\n",
    "- Step 3: Distance = Speed × Time\n",
    "- Step 4: 60 × 2 = 120 km\n",
    "Final answer: 120 km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMs in Action - Applications in Basic Sciences and Research\n",
    "\n",
    "LLMs are not just for chatbots and creative writing. They are rapidly becoming powerful tools for scientists and researchers. Here are a few examples:\n",
    "\n",
    "*   **Accelerating Literature Reviews:** Scientists can use LLMs to quickly scan and summarize vast amounts of research papers, helping them stay up-to-date with the latest findings in their field.\n",
    "*   **Generating Hypotheses:** By analyzing existing data, LLMs can identify patterns and connections that might not be obvious to human researchers, leading to new and innovative hypotheses.\n",
    "*   **Data Analysis and Interpretation:** In fields like genomics and climate science that generate massive datasets, LLMs can help researchers identify patterns, anomalies, and correlations.\n",
    "*   **Drug Discovery and Protein Engineering:** LLMs are being used to accelerate drug discovery and even design new protein sequences with specific functions.\n",
    "*   **Code Generation:** Researchers can use LLMs to generate code for data analysis and visualization, saving time and effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example in Action: AlphaFold\n",
    "\n",
    "While not a traditional text-based LLM, DeepMind's AlphaFold uses similar deep learning principles to predict the 3D structure of proteins from their amino acid sequence. This has been a monumental breakthrough in biology and medicine.\n",
    "\n",
    "![AlphaFold Protein Prediction](https://www.nature.com/immersive/d41586-022-03535-7/assets/M22A2pGZJ7/2022-11-21-protein-folding-1920x1080.gif)\n",
    "*An animation from Nature showing how a protein folds into its complex 3D shape, a problem now largely solved by AI.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations & Ethics\n",
    "\n",
    "- Hallucinations: LLMs can make up facts.\n",
    "\n",
    "- Bias: Reflect biases present in training data.\n",
    "\n",
    "- Cost: Training large models requires huge computational resources.\n",
    "\n",
    "Exercise 5: Find the projected electricity compsumption for LLM and compare with the actual human capacity to produce electricity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Current\" offering\n",
    "<https://epoch.ai/data-insights/llm-apis-accuracy-runtime-tradeoff>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Exercises\n",
    "\n",
    "Now it's your turn to explore the world of LLMs! Here are a few exercises to get you started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise 1: Become a Prompt Engineer**\n",
    "\n",
    "The way you phrase your request to an LLM (the \"prompt\") can have a big impact on the quality of the response. Experiment with different ways of asking the same question. \n",
    "\n",
    "**Task:** Pick a scientific concept (e.g., photosynthesis, black holes, gene editing). Ask an LLM to explain it using at least three different prompts.\n",
    "\n",
    "1.  **Simple Prompt:** `\"Tell me about photosynthesis.\"`\n",
    "2.  **Role-playing Prompt:** `\"You are a science teacher. Explain photosynthesis to a 10-year-old.\"`\n",
    "3.  **Detailed Prompt:** `\"Provide a detailed, scientific explanation of the chemical reactions, inputs, and outputs involved in photosynthesis for a university-level biology student.\"`\n",
    "\n",
    "In the cell below, write down your prompts and compare the outputs. What are the key differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to write your observations for Exercise 1.\n",
    "# You can change it to a Markdown cell if you prefer.\n",
    "\n",
    "prompt_1_output = \"...\"\n",
    "prompt_2_output = \"...\"\n",
    "prompt_3_output = \"...\"\n",
    "\n",
    "print(\"Observation: The role-playing prompt gave a much simpler analogy, while the detailed prompt included specific chemical formulas...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise 2: Explore Different LLMs**\n",
    "\n",
    "There are many different LLMs available to the public (e.g., Gemini, ChatGPT, Claude, Llama). \n",
    "\n",
    "**Task:** Try out a few different ones. Give them the same prompt and compare their responses. \n",
    "\n",
    "**Prompt idea:** `\"Write a short story in the style of Isaac Asimov about a scientist who discovers that their lab's AI has become self-aware.\"`\n",
    "\n",
    "Do you notice any differences in their style, tone, creativity, or accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise 3: Investigate a Scientific Application**\n",
    "\n",
    "**Task:** Choose a scientific field that interests you (e.g., climate science, neuroscience, archaeology, materials science) and do a quick search to see how LLMs are being used in that area. \n",
    "\n",
    "**Search terms to try:**\n",
    "*   `\"large language models in climate science\"`\n",
    "*   `\"AI for drug discovery\"`\n",
    "*   `\"using LLMs to analyze historical texts\"`\n",
    "\n",
    "In the cell below, write a short summary (3-4 sentences) of the most interesting application you find. Include a link to the article or paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your summary for Exercise 3 here.\n",
    "field = \"Neuroscience\"\n",
    "application_summary = \"I found that researchers are using LLMs to analyze patient interviews to identify early signs of neurodegenerative diseases like Alzheimer's. The models can detect subtle changes in language patterns that are not easily noticeable by humans.\"\n",
    "link = \"https://www.example.com/link-to-article\"\n",
    "\n",
    "print(f\"Field: {field}\\nSummary: {application_summary}\\nLink: {link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise 4: Try a Coding Challenge (Optional)**\n",
    "\n",
    "If you have some programming experience (Python is great for this), try using an LLM to help you with a coding challenge.\n",
    "\n",
    "**Task:** Ask an LLM to write a Python function for a simple task. For example:\n",
    "`\"Write a Python function that takes a list of numbers and returns a new list containing only the prime numbers.\"`\n",
    "\n",
    "Then, copy the code into the cell below and run it to see if it works. Can you ask the LLM to add comments to the code to explain how it works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the Python code from the LLM here to test it.\n",
    "\n",
    "# Example code that an LLM might generate:\n",
    "def is_prime(n):\n",
    "    \"\"\"Checks if a number is prime.\"\"\"\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def filter_primes(numbers):\n",
    "    \"\"\"Filters a list of numbers to return only the primes.\"\"\"\n",
    "    return [num for num in numbers if is_prime(num)]\n",
    "\n",
    "# Test the function\n",
    "my_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "prime_numbers = filter_primes(my_list)\n",
    "print(f\"Original list: {my_list}\")\n",
    "print(f\"Prime numbers: {prime_numbers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise 5: Think Critically**\n",
    "\n",
    "As you use LLMs, it's important to think critically about the information they provide. They are trained on data from the internet, which can contain biases and inaccuracies. They can also \"hallucinate\" or make up facts.\n",
    "\n",
    "**Task:** Ask an LLM a question about a very recent event (something that happened in the last 24 hours) or a very niche, specific topic. \n",
    "\n",
    "1.  What is its response?\n",
    "2.  Can you verify the information using a reliable source (like a major news website or a scientific journal)?\n",
    "3.  Does the LLM cite its sources? \n",
    "\n",
    "This exercise highlights the importance of always double-checking important information from LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### References\n",
    "\n",
    "1. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. In *Advances in neural information processing systems* (pp. 5998-6008).\n",
    "2. Shazeer, N., Mirhoseini, A., Maziarz, K., Davis, A., Le, Q., Hinton, G., & Dean, J. (2017). Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. *arXiv preprint arXiv:1701.06538*.\n",
    "3. Park, P. S., Goldstein, J. A., O'Gara, A., Chen, M., & Hendrycks, D. (2023). AI Deception: A Survey of Examples, Risks, and Potential Solutions. *arXiv preprint arXiv:2308.14752*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful AI tools\n",
    "- notebooklm\n",
    "- local models\n",
    "- Other llm: claude, gemini (unal account)\n",
    "- Agents\n",
    "- Google co-scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
