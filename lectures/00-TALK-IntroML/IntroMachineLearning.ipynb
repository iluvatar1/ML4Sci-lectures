{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# A fast introduction to Machine Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Introduction to Machine Learning\n",
    "\n",
    "> Machine learning is the field of study that gives computers the ability\n",
    "to learn without being explicitly programmed. Arthur Samuel, 1959\n",
    "\n",
    "Learning:\n",
    "> A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E. Tom Mitchellâ€™s, 1997\n",
    " \n",
    "Machine learning is a branch of artificial intelligence that allows computers to learn from given information and perform new but similar tasks. \n",
    "\n",
    "<img src=\"figs/AI-ML.png\" alt=\"transistors-per-microprocessor.png\" width=\"50%\" align=\"center\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Artificial intelligence**: The computer performs actions defined as requiring intelligence -> Moving target\n",
    "- Search Based Heuristic Optimization\n",
    "- Evolutionary computation\n",
    "- Logic Programming (inductive logic programming, fuzzy logic)\n",
    "- robabilistic Reasoning Under Uncertainty (bayesian networks)\n",
    "- Computer Vision\n",
    "- Natural Language Processing\n",
    "- Robotics\n",
    "- Machine Learning\n",
    "\n",
    "Examples:\n",
    "- Self-driving cars\n",
    "- ChatGPT (LLM)\n",
    "- Healthcare: Diagnosis from scans\n",
    "- Finance: Fraud detection\n",
    "- Retail: Recommender systems\n",
    "- Transport: Autonomous vehicles\n",
    "- Creativity: AI art, music, writing\n",
    "\n",
    "\n",
    "<!-- <div style=\"text-align: center;\">\n",
    "    <img src=\"figs/AI-ML.png\" alt=\"Machine learning as a subarea of artificail intelligence. From: Understanding Deep Learning, Simon J.D. Prince\" width=\"600\">\n",
    "    <figcaption>From: Understanding Deep Learning, Simon J.D. Prince</figcaption>\n",
    "</div> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Historical development\n",
    "- https://letsdatascience.com/learn/history/history-of-machine-learning/\n",
    "- https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/2-history-of-ML/README.md\n",
    "- https://www.inveniam.fr/a-brief-history-of-machine-learning\n",
    "- https://ahistoryofai.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Hardware was too costly, but improvements on both cpu and gpu made it practical, or at least attainable, to apply the different AI models.\n",
    "\n",
    "<img src=\"figs/transistors-per-microprocessor.png\" alt=\"transistor versus microprocesos\" width=\"60%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://epochai.org/assets/images/posts/2022/gpu-perf/gpu-perf-banner.png\" alt=\"gpu-perf over time\" style=\"width: 80%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Is this the future? <https://ai-2027.com/>\n",
    "<div style=\"text-align: center;\">\n",
    "<figure>\n",
    "<img src=\"https://ai-2027.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FepochLLMprice-nowatermark.824fa343.png&w=1920&q=75\" width=60%>\n",
    "<figcaption> https://ai-2027.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FepochLLMprice-nowatermark.824fa343.png&w=1920&q=75 </figcaption>\n",
    "</figure>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Where to Find Data in the Basic and Natural Sciences\n",
    "\n",
    "Finding high-quality, publicly available data is a crucial skill for any scientist. Data is often stored in repositories, which can be general-purpose or field-specific. The articles mentioned previously likely sourced their data from a mix of their own experiments and public databases like these.\n",
    "General-Purpose Scientific Data Repositories\n",
    "\n",
    "These platforms host datasets from a wide variety of scientific fields. They are often used when a field-specific repository doesn't exist or as a requirement for publication in many journals.\n",
    "\n",
    "- Zenodo: (<https://zenodo.org/>)\n",
    "\n",
    "A general-purpose repository operated by CERN. It accepts data from all fields of science and provides a DOI for every upload, making the data citable.\n",
    "\n",
    "- Figshare: (<https://figshare.com/>)\n",
    "\n",
    "A platform where researchers can make all of their research outputs available in a citable, shareable, and discoverable manner. It hosts figures, datasets, posters, and code.\n",
    "\n",
    "- Dryad: (<https://datadryad.org/>)\n",
    "\n",
    "A curated general-purpose repository that makes the data underlying scientific publications discoverable, freely reusable, and citable. It has strong ties to the biosciences but is open to all fields.\n",
    "\n",
    "### Field-Specific Databases\n",
    "\n",
    "These are highly curated databases focused on a single area of research.\n",
    "\n",
    "#### Genomics and Molecular Biology:\n",
    "\n",
    "- NCBI (National Center for Biotechnology Information): (<https://www.ncbi.nlm.nih.gov/>) A suite of databases, including:\n",
    "\n",
    "    Gene Expression Omnibus (GEO): For gene expression data from microarrays and sequencing.\n",
    "\n",
    "    Sequence Read Archive (SRA): For raw sequencing data from next-generation sequencers.\n",
    "\n",
    "- Protein Data Bank (PDB): (<https://www.rcsb.org/>) A database of 3D structural data for large biological molecules like proteins and nucleic acids. This is essential for the kind of molecular dynamics work mentioned in the Sfriso & Crave paper.\n",
    "\n",
    "#### Environmental and Earth Sciences:\n",
    "\n",
    "- USGS (U.S. Geological Survey) Data Releases: (<https://www.usgs.gov/data>) Provides public access to water data (matching the Kaur & Godara study), geological data (relevant to the Kahangwa study), and more.\n",
    "\n",
    "- NOAA (National Oceanic and Atmospheric Administration): (<https://www.noaa.gov/data>) The primary source for climate, weather, and oceanographic data.\n",
    "\n",
    "- Copernicus: (<https://www.copernicus.eu/en>) The European Union's Earth observation programme, providing vast amounts of satellite imagery and environmental data.\n",
    "\n",
    "#### Astronomy and Physics:\n",
    "\n",
    "Sloan Digital Sky Survey (SDSS): (<https://www.sdss.org/>) A massive survey that has created the most detailed three-dimensional maps of the Universe ever made. It provides images and spectra for millions of celestial objects. (We will use this for our example).\n",
    "\n",
    "MAST (Mikulski Archive for Space Telescopes): (<https://mast.stsci.edu/>) The official data archive for NASA's Hubble, James Webb, and other space telescopes.\n",
    "\n",
    "ESO Science Archive Facility: (<http://archive.eso.org/>) The data archive for the European Southern Observatory's telescopes, including the Very Large Telescope (VLT).\n",
    "\n",
    "#### Chemistry:\n",
    "\n",
    "- PubChem: (<https://pubchem.ncbi.nlm.nih.gov/>) A massive database of chemical molecules and their activities against biological assays.\n",
    "\n",
    "- Spectral Database for Organic Compounds (SDBS): (<https://sdbs.db.aist.go.jp/>) A free database containing various types of spectra (MS, NMR, IR, Raman) for thousands of organic compounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Types of learning\n",
    "<img src=\"./figs/AI-ML.png\" alt=\"ML trends\" width=40% align=\"center\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML in science\n",
    "<https://mailchi.mp/quantamagazine.org/how-physics-made-modern-ai-possible?e=7add59a1e9>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Practical, short, fast example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Data creation\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "X, y = make_blobs(n_samples=100, centers=2, random_state=42)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr')\n",
    "plt.title(\"Input data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Supervised\n",
    "- Learn from labeled examples\n",
    "- Task: Prediction (classification or regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Train a classifier\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Plot decision boundary\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='bwr')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr')\n",
    "plt.title(\"Supervised Learning: Logistic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Unsupervised \n",
    "- No labels, find structure in data\n",
    "- Task: Clustering or dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "preds = kmeans.predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=preds, cmap='cool')\n",
    "plt.title(\"Unsupervised: K-means Clustering\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Reinforcement learning\n",
    "- Learn by trial and error\n",
    "- Agent interacts with environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src=\"https://www.youtube.com/embed/L_4BPjLBF4E?si=4vNIAkUAz7tkTyiO\", width=\"560\", height=\"315\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Typical workflow\n",
    "<img src=\"./figs/ML-workflow.png\" alt=\"ML workflow\" width=\"50%\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "1. **Dataset Collection**: Depends on the experiment or goals. What kind of data ? (categorical numerical) How much data? Units? reference data? data base? Data storage/access? \n",
    "2. **Dataset preprocessing**: Cleaning data. Missing data. Noise. Outliers. Normalization. Training and test sets. Or Train, validation (for hyper parameters), and test set. \n",
    "3. **Model training**: Depends on the actual approach. For supervised learning we need both input and output values. For unsupervised only input. No underfitting or overfitting. \n",
    "4. **Model evaluation**: Testing the training success, with some defined metrics. Maybe needs to redo some previous steps.\n",
    "\n",
    "### Core concepts\n",
    "- **Data**: examples used for learning\n",
    "- **Features**: inputs (e.g., age, temperature, pixels)\n",
    "- **Model**: function that maps input to output\n",
    "- **Training**: adjusting model to reduce error\n",
    "- **Testing**: evaluate model on new data\n",
    "- **Meta-Parameters**: Parameters controlling the model\n",
    "\n",
    "Beware of under/over fitting : See also last part of <https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "x = np.linspace(0, 6, 30)\n",
    "y = np.sin(x) + 0.3 * np.random.randn(30)\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "# True function\n",
    "x_plot = np.linspace(0, 6, 100).reshape(-1, 1)\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "# Underfitting (degree=1)\n",
    "plt.subplot(1, 3, 1)\n",
    "model_under = make_pipeline(PolynomialFeatures(1), LinearRegression())\n",
    "model_under.fit(X, y)\n",
    "plt.scatter(x, y, label='data')\n",
    "plt.plot(x_plot, np.sin(x_plot), label='true function')\n",
    "plt.plot(x_plot, model_under.predict(x_plot), label='underfit model')\n",
    "plt.title(\"Underfitting\")\n",
    "plt.legend()\n",
    "\n",
    "# Good fit (degree=3)\n",
    "plt.subplot(1, 3, 2)\n",
    "model_good = make_pipeline(PolynomialFeatures(3), LinearRegression())\n",
    "model_good.fit(X, y)\n",
    "plt.scatter(x, y, label='data')\n",
    "plt.plot(x_plot, np.sin(x_plot), label='true function')\n",
    "plt.plot(x_plot, model_good.predict(x_plot), label='good fit')\n",
    "plt.title(\"Good Fit\")\n",
    "plt.legend()\n",
    "\n",
    "# Overfitting (degree=15)\n",
    "plt.subplot(1, 3, 3)\n",
    "model_over = make_pipeline(PolynomialFeatures(15), LinearRegression())\n",
    "model_over.fit(X, y)\n",
    "plt.scatter(x, y, label='data')\n",
    "plt.plot(x_plot, np.sin(x_plot), label='true function')\n",
    "plt.plot(x_plot, model_over.predict(x_plot), label='overfit model')\n",
    "plt.title(\"Overfitting, poor generalization\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## ML Algorithms\n",
    "- https://www.datacamp.com/cheat-sheet/machine-learning-cheat-sheet\n",
    "- https://sites.google.com/view/datascience-cheat-sheets\n",
    "- https://github.com/SamBelkacem/AI-ML-cheatsheets\n",
    "- https://www.naftaliharris.com/blog/visualizing-k-means-clustering/\n",
    "\n",
    "<img src=\"./figs/ML-CheatSheet-01.webp\" alt=\"Some algs ML\" width=\"50%\" align=\"center\">\n",
    "\n",
    "<img src=\"./figs/ML-Cheat-Sheet_2.png\" alt=\"ML cheatsheet\" width=\"50%\" align=\"center\">\n",
    "\n",
    "\n",
    "### Classifier comparison:\n",
    "<https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html>\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_classifier_comparison_001.png\" alt=\"Classifiers\" width=\"80%\" align=\"center\">\n",
    "\n",
    "### Tensor flow playground\n",
    "Try: <https://playground.tensorflow.org>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
