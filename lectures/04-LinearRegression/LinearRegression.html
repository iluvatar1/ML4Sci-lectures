
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>8. An Introduction to Linear Regression &#8212; Introduction to Machine Learning for Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles.css?v=76e7d31e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/04-LinearRegression/LinearRegression';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="9. What is a Neural Network?" href="../07-IntroNeuralNetworks/NeuralNetworks-BasicConcepts.html" />
    <link rel="prev" title="7. Principal Component Analysis (PCA)" href="../03-PCA/PCA.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../README.html">
  
  
  
  
  
  
    <p class="title logo__title">Introduction to Machine Learning for Science</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../README.html">
                    Introduction to Machine Learning for Science
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../00-IntroductionCourseML/IntroCourse-MachineLearning.html">1. Introduction to the course and to Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00-TALK-IntroML/IntroMachineLearning.html">2. A fast introduction to Machine Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Python review</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../01-reviewPython/01-IntroProgrammingPython.html">3. Python Programming (very fast) Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01-reviewPython/02-IntroProgrammingPython-DataStructs.html">4. Intro Python II: python data structures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01-reviewPython/pandas-intro.html">5. Pandas Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02-LimpiezayPrepDatos/TutorialPandas.html">6. Pandas for data cleaning and analysis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Supervised learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../03-PCA/PCA.html">7. Principal Component Analysis (PCA)</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">8. An Introduction to Linear Regression</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../07-IntroNeuralNetworks/NeuralNetworks-BasicConcepts.html">9. What is a Neural Network?</a></li>

</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/iluvatar1/ML4Sci-lectures/master?urlpath=lab/tree/lectures/04-LinearRegression/LinearRegression.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/iluvatar1/ML4Sci-lectures/blob/master/github/iluvatar1/ML4Sci-lectures/blob/master/lectures/04-LinearRegression/LinearRegression.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/iluvatar1/ML4Sci-lectures" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/iluvatar1/ML4Sci-lectures/issues/new?title=Issue%20on%20page%20%2Flectures/04-LinearRegression/LinearRegression.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/lectures/04-LinearRegression/LinearRegression.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>An Introduction to Linear Regression</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#review-what-is-machine-learning">8.1. Review: What is Machine Learning?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-learning">8.2. Supervised Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-regression-predicting-a-continuous-value">8.2.1. A. Regression: Predicting a Continuous Value</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-classification-predicting-a-discrete-category">8.2.2. B. Classification: Predicting a Discrete Category</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression">8.3. Linear Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-goal">8.3.1. The Goal</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-find-the-best-line">8.4. How Do We Find the “Best” Line?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization-with-gradient-descent">8.4.1. Optimization with Gradient Descent</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-physics-example-hooke-s-law">8.5. A Physics Example - Hooke’s Law</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-generation">8.5.1. Data Generation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-using-sklearn">8.5.2. Linear regression using <code class="docutils literal notranslate"><span class="pre">sklearn</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practice-exercises">8.6. Practice Exercises</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tensorflow-pytorch">8.6.1. Tensorflow/pytorch</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#biology-brain-vs-body-weight">8.6.2. Biology - Brain vs. Body Weight</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-what-s-next">8.7. Conclusion &amp; What’s Next?</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="an-introduction-to-linear-regression">
<h1><span class="section-number">8. </span>An Introduction to Linear Regression<a class="headerlink" href="#an-introduction-to-linear-regression" title="Link to this heading">#</a></h1>
<hr class="docutils" />
<p><strong>Goal:</strong> By the end of this session, you will understand the core concepts of supervised learning, know the difference between regression and classification, and be able to build, train, and interpret a simple Linear Regression model using Python.</p>
<section id="review-what-is-machine-learning">
<h2><span class="section-number">8.1. </span>Review: What is Machine Learning?<a class="headerlink" href="#review-what-is-machine-learning" title="Link to this heading">#</a></h2>
<p>At its core, <strong>Machine Learning (ML)</strong> is the science of getting computers to learn and act like humans do, and improve their learning over time in an autonomous fashion, by feeding them data and information in the form of observations and real-world interactions.</p>
<ol class="arabic simple">
<li><p><strong>Supervised Learning:</strong> Learning from data that is <strong>labeled</strong>. You provide the algorithm with examples of inputs and their corresponding correct outputs. The goal is to learn a general rule that maps inputs to outputs. (This is our focus today).</p></li>
<li><p><strong>Unsupervised Learning:</strong> Learning from data that is <strong>unlabeled</strong>. The algorithm tries to find patterns, structures, or clusters in the data on its own.</p></li>
<li><p><strong>Reinforcement Learning:</strong> An agent learns to perform actions in an environment to maximize a cumulative reward. It learns by trial and error.</p></li>
</ol>
</section>
<section id="supervised-learning">
<h2><span class="section-number">8.2. </span>Supervised Learning<a class="headerlink" href="#supervised-learning" title="Link to this heading">#</a></h2>
<blockquote>
<div><p><strong>Supervised Learning:</strong> Given a dataset of input features <strong>X</strong> and corresponding output labels <strong>y</strong>, we want to learn a function <code class="docutils literal notranslate"><span class="pre">h</span></code> (for hypothesis) such that <code class="docutils literal notranslate"><span class="pre">h(X)</span></code> is a good predictor for <strong>y</strong>.</p>
</div></blockquote>
<p>There are two primary types of supervised learning problems:</p>
<section id="a-regression-predicting-a-continuous-value">
<h3><span class="section-number">8.2.1. </span>A. Regression: Predicting a Continuous Value<a class="headerlink" href="#a-regression-predicting-a-continuous-value" title="Link to this heading">#</a></h3>
<p>The output <code class="docutils literal notranslate"><span class="pre">y</span></code> is a continuous, numerical value.</p>
<ul class="simple">
<li><p><strong>Question:</strong> Based on a material’s temperature, what will its electrical resistance be?</p></li>
<li><p><strong>Question:</strong> Given the mass of a star, what is its expected luminosity?</p></li>
<li><p><strong>Our main tool today:</strong> <strong>Linear Regression</strong> See <a class="reference external" href="https://www.youtube.com/watch?v=CtsRRUddV2s">Visually Explained: Linear regression</a></p></li>
</ul>
</section>
<section id="b-classification-predicting-a-discrete-category">
<h3><span class="section-number">8.2.2. </span>B. Classification: Predicting a Discrete Category<a class="headerlink" href="#b-classification-predicting-a-discrete-category" title="Link to this heading">#</a></h3>
<p>The output <code class="docutils literal notranslate"><span class="pre">y</span></code> is a discrete category or class label.</p>
<ul class="simple">
<li><p><strong>Question:</strong> Based on a cell’s size and shape, is it cancerous or benign?</p></li>
<li><p><strong>Question:</strong> Given the energy and momentum from a particle collider, did we detect an electron or a muon?</p></li>
<li><p><strong>A common tool:</strong> <strong>Logistic Regression</strong> (despite its name, it’s for classification!)</p></li>
</ul>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Feature</p></th>
<th class="head text-left"><p>Linear Regression</p></th>
<th class="head text-left"><p>Logistic Regression</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>Problem Type</strong></p></td>
<td class="text-left"><p>Regression (predicting continuous values)</p></td>
<td class="text-left"><p>Classification (predicting categorical outcomes)</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Output</strong></p></td>
<td class="text-left"><p>Continuous numerical value (e.g., price, temperature)</p></td>
<td class="text-left"><p>Probability (0 to 1), which is then mapped to a class</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Dependent Variable</strong></p></td>
<td class="text-left"><p>Continuous</p></td>
<td class="text-left"><p>Categorical (binary or multi-class)</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Underlying Function</strong></p></td>
<td class="text-left"><p>Linear equation: y=β0​+β1​x1​+…+βn​xn​</p></td>
<td class="text-left"><p>Sigmoid (logistic) function applied to a linear equation: p=1+e−(β0​+β1​x1​+…+βn​xn​)1​</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Cost Function</strong></p></td>
<td class="text-left"><p>Mean Squared Error (MSE), Root Mean Squared Error (RMSE)</p></td>
<td class="text-left"><p>Log Loss (Binary Cross-Entropy), Cross-Entropy</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Interpretation of Coefficients</strong></p></td>
<td class="text-left"><p>Change in the dependent variable for a one-unit change in the independent variable</p></td>
<td class="text-left"><p>Change in the log-odds of the dependent variable for a one-unit change in the independent variable</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Assumptions</strong></p></td>
<td class="text-left"><p>Linearity, independence of errors, homoscedasticity, normality of residuals, no multicollinearity</p></td>
<td class="text-left"><p>Linearity of independent variables with log-odds, independence of observations, no multicollinearity</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Common Use Cases</strong></p></td>
<td class="text-left"><p>Predicting house prices, sales forecasting, predicting exam scores, trend analysis</p></td>
<td class="text-left"><p>Spam detection, disease prediction (e.g., presence/absence), customer churn prediction, sentiment analysis</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Evaluation Metrics</strong></p></td>
<td class="text-left"><p>MSE, RMSE, R-squared, MAE</p></td>
<td class="text-left"><p>Accuracy, Precision, Recall, F1-Score, ROC-AUC</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="linear-regression">
<h2><span class="section-number">8.3. </span>Linear Regression<a class="headerlink" href="#linear-regression" title="Link to this heading">#</a></h2>
<p>Linear Regression is one of the simplest and most interpretable machine learning models. It assumes a linear relationship between the input features and the output variable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">aux.linear_regression_example_plot</span><span class="w"> </span><span class="kn">import</span> <span class="n">generate_and_plot_regression_problems</span>
<span class="n">fig_regression_problems</span> <span class="o">=</span> <span class="n">generate_and_plot_regression_problems</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">from</span><span class="w"> </span><span class="nn">aux.linear_regression_example_plot</span><span class="w"> </span><span class="kn">import</span> <span class="n">generate_and_plot_regression_problems</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">fig_regression_problems</span> <span class="o">=</span> <span class="n">generate_and_plot_regression_problems</span><span class="p">()</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;aux.linear_regression_example_plot&#39;
</pre></div>
</div>
</div>
</div>
<section id="the-goal">
<h3><span class="section-number">8.3.1. </span>The Goal<a class="headerlink" href="#the-goal" title="Link to this heading">#</a></h3>
<p>To find the “best-fit” line that describes the data. For a single input feature <code class="docutils literal notranslate"><span class="pre">x</span></code>, the equation of the line is:</p>
<div class="math notranslate nohighlight">
\[ \hat{y} = \theta_0 + \theta_1 x \]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{y}\)</span> (y-hat) is the <strong>predicted value</strong>.</p></li>
<li><p><span class="math notranslate nohighlight">\(x\)</span> is the <strong>input feature</strong>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\theta_0\)</span> (theta-zero) is the <strong>y-intercept</strong> (also called the bias). It’s the value of <span class="math notranslate nohighlight">\(\hat{y}\)</span> when <span class="math notranslate nohighlight">\(x=0\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\theta_1\)</span> (theta-one) is the <strong>slope</strong> or <strong>coefficient</strong>. It represents the change in <span class="math notranslate nohighlight">\(\hat{y}\)</span> for a one-unit change in <span class="math notranslate nohighlight">\(x\)</span>.</p></li>
</ul>
<p>Our goal is to find the optimal values for <span class="math notranslate nohighlight">\(\theta_0\)</span> and <span class="math notranslate nohighlight">\(\theta_1\)</span> that make our line fit the data as closely as possible. Notice that it is possible to also add non-linear relationships even if the method is called linear regression.</p>
<blockquote>
<div><p><strong>Note</strong> In ML, We can apply linear regression to non-linear problems</p>
</div></blockquote>
</section>
</section>
<section id="how-do-we-find-the-best-line">
<h2><span class="section-number">8.4. </span>How Do We Find the “Best” Line?<a class="headerlink" href="#how-do-we-find-the-best-line" title="Link to this heading">#</a></h2>
<p>We need a way to quantify how “wrong” our line is. We do this with a <strong>Cost Function</strong> (or Loss Function).</p>
<ol class="arabic simple">
<li><p>For each data point <span class="math notranslate nohighlight">\((x_i, y_i)\)</span>, we calculate the difference between the <strong>actual value</strong> (<span class="math notranslate nohighlight">\(y_i\)</span>) and the <strong>predicted value</strong> (<span class="math notranslate nohighlight">\(\hat{y}_i\)</span>). This difference is called the <strong>residual</strong> or <strong>error</strong>.</p></li>
<li><p>We square these errors (so positive and negative errors don’t cancel out) and sum them up.</p></li>
<li><p>We take the average.</p></li>
</ol>
<p>This gives us the <strong>Mean Squared Error (MSE)</strong> cost function:</p>
<div class="math notranslate nohighlight">
\[ J(\theta_0, \theta_1) = \frac{1}{2m} \sum_{i=1}^{m} (\hat{y}_i - y_i)^2 = \frac{1}{2m} \sum_{i=1}^{m} ((\theta_0 + \theta_1 x_i) - y_i)^2 \]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(m\)</span> is the number of data points.</p></li>
<li><p><span class="math notranslate nohighlight">\(J(\theta_0, \theta_1)\)</span> is the cost for a specific choice of <span class="math notranslate nohighlight">\(\theta_0\)</span> and <span class="math notranslate nohighlight">\(\theta_1\)</span>.</p></li>
</ul>
<p>Our goal is to find the values of <span class="math notranslate nohighlight">\(\theta_0\)</span> and <span class="math notranslate nohighlight">\(\theta_1\)</span> that <strong>minimize</strong> this cost function <span class="math notranslate nohighlight">\(J\)</span>.</p>
<section id="optimization-with-gradient-descent">
<h3><span class="section-number">8.4.1. </span>Optimization with Gradient Descent<a class="headerlink" href="#optimization-with-gradient-descent" title="Link to this heading">#</a></h3>
<p>How do we find the minimum of the cost function? We use an algorithm called <strong>Gradient Descent</strong>.</p>
<p><strong>Analogy:</strong> Imagine you are a hiker in a foggy valley and you want to get to the lowest point. You can’t see the whole valley, but you can feel the slope of the ground right under your feet. What do you do? You take a step in the steepest downward direction.</p>
<p>This is exactly what Gradient Descent does:</p>
<ol class="arabic simple">
<li><p>Start with some random values for <span class="math notranslate nohighlight">\(\theta_0\)</span> and <span class="math notranslate nohighlight">\(\theta_1\)</span>.</p></li>
<li><p>Calculate the gradient (the “slope”) of the cost function at that point.</p></li>
<li><p>Take a small step in the opposite direction of the gradient (downhill).</p></li>
<li><p>Repeat until you reach the bottom (the minimum), where the slope is zero.</p></li>
</ol>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>For a nice visualization of gradient descent, check: <a class="reference external" href="https://aero-learn.imperial.ac.uk/vis/Machine%20Learning/gradient_descent_3d.html">https://aero-learn.imperial.ac.uk/vis/Machine Learning/gradient_descent_3d.html</a></p>
</div>
<p>The size of the “step” you take is called the <strong>learning rate</strong> (alpha, <span class="math notranslate nohighlight">\(\alpha\)</span>). A small learning rate will converge slowly, while a large one might overshoot the minimum. See <a class="reference external" href="https://www.youtube.com/watch?v=gsfbWn4Gy5Q">https://www.youtube.com/watch?v=gsfbWn4Gy5Q</a></p>
</section>
</section>
<section id="a-physics-example-hooke-s-law">
<h2><span class="section-number">8.5. </span>A Physics Example - Hooke’s Law<a class="headerlink" href="#a-physics-example-hooke-s-law" title="Link to this heading">#</a></h2>
<p>Hooke’s Law is a fundamental principle in physics that states the force (<code class="docutils literal notranslate"><span class="pre">F</span></code>) needed to extend or compress a spring by some distance (<code class="docutils literal notranslate"><span class="pre">x</span></code>) is directly proportional to that distance.</p>
<div class="math notranslate nohighlight">
\[ F = kx \]</div>
<p>This is a perfect linear relationship! We can use linear regression to find the spring constant <code class="docutils literal notranslate"><span class="pre">k</span></code> from experimental data. Let’s assume we conducted an experiment and got some noisy measurements.</p>
<section id="data-generation">
<h3><span class="section-number">8.5.1. </span>Data Generation<a class="headerlink" href="#data-generation" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Step 1: Generate some experimental data</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Let&#39;s assume the true spring constant k is 4.5 N/m</span>
<span class="n">k_true</span> <span class="o">=</span> <span class="mf">4.5</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span> <span class="c1"># for reproducibility</span>

<span class="c1"># Displacement (x) in meters. This is our feature X.</span>
<span class="c1"># The .reshape(-1, 1) is needed because scikit-learn expects 2D arrays for features.</span>
<span class="n">x_displacement</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Force (F) in Newtons. This is our target y.</span>
<span class="c1"># We&#39;ll calculate the true force and add some random &quot;measurement noise&quot;</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">x_displacement</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">y_force</span> <span class="o">=</span> <span class="n">k_true</span> <span class="o">*</span> <span class="n">x_displacement</span> <span class="o">+</span> <span class="n">noise</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Step 2: Setup visualization </span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Set up plots for a nice look</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-v0_8-darkgrid&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;font.size&#39;</span><span class="p">:</span> <span class="mi">14</span><span class="p">,</span> <span class="s1">&#39;figure.figsize&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">)})</span>

<span class="c1"># Step 3: Visualize the data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_displacement</span><span class="p">,</span> <span class="n">y_force</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Experimental Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Displacement (x) [m]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Force (F) [N]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Hooke&#39;s Law: Force vs. Displacement&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>This looks like a good candidate for linear regression! The data points roughly follow a straight line.</p>
</section>
<section id="linear-regression-using-sklearn">
<h3><span class="section-number">8.5.2. </span>Linear regression using <code class="docutils literal notranslate"><span class="pre">sklearn</span></code><a class="headerlink" href="#linear-regression-using-sklearn" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Build and train the model using Scikit-Learn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span>

<span class="c1"># Create a linear regression model object</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

<span class="c1"># Train the model using our data</span>
<span class="c1"># The .fit() method is where the &#39;learning&#39; (Gradient Descent) happens!</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_displacement</span><span class="p">,</span> <span class="n">y_force</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Analyze the results</span>

<span class="c1"># Get the learned parameters (theta_0 and theta_1)</span>
<span class="c1"># .intercept_ is an array, so we take the first element</span>
<span class="n">theta_0</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># .coef_ is a 2D array, so we access it with [0][0]</span>
<span class="n">theta_1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The model has learned the following equation:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Force = </span><span class="si">{</span><span class="n">theta_0</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="n">theta_1</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> * Displacement</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The estimated spring constant (k) is: </span><span class="si">{</span><span class="n">theta_1</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> N/m&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The true spring constant was: </span><span class="si">{</span><span class="n">k_true</span><span class="si">}</span><span class="s2"> N/m&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>That’s pretty close! Our model successfully estimated the spring constant from the noisy data. The small non-zero intercept <code class="docutils literal notranslate"><span class="pre">theta_0</span></code> is a result of the random noise we added; in a perfect world, it would be zero.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize the model&#39;s fit</span>

<span class="c1"># Generate predictions from our model for the x values</span>
<span class="n">y_predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_displacement</span><span class="p">)</span>

<span class="c1"># Plot the original data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_displacement</span><span class="p">,</span> <span class="n">y_force</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Experimental Data&#39;</span><span class="p">)</span>

<span class="c1"># Plot the regression line</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_displacement</span><span class="p">,</span> <span class="n">y_predicted</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Linear Regression Fit&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Displacement (x) [m]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Force (F) [N]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Hooke&#39;s Law with Model Fit&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="practice-exercises">
<h2><span class="section-number">8.6. </span>Practice Exercises<a class="headerlink" href="#practice-exercises" title="Link to this heading">#</a></h2>
<p>Now it’s your turn! Apply what you’ve learned to new scientific datasets.</p>
<section id="tensorflow-pytorch">
<h3><span class="section-number">8.6.1. </span>Tensorflow/pytorch<a class="headerlink" href="#tensorflow-pytorch" title="Link to this heading">#</a></h3>
<p>Implement the same example but using <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code> and <code class="docutils literal notranslate"><span class="pre">pytorch</span></code>. Compare easy of use.</p>
</section>
<section id="biology-brain-vs-body-weight">
<h3><span class="section-number">8.6.2. </span>Biology - Brain vs. Body Weight<a class="headerlink" href="#biology-brain-vs-body-weight" title="Link to this heading">#</a></h3>
<p>Allometry is the study of the relationship of body size to shape, anatomy, and physiology. It is a well-known fact that the brain weight of mammals generally increases with body weight. Let’s model this relationship.</p>
<p><strong>Task:</strong></p>
<ol class="arabic simple">
<li><p>Load the provided data for various mammal species.</p></li>
<li><p>The relationship is often modeled on a log-log scale. Transform both <code class="docutils literal notranslate"><span class="pre">body_wt</span></code> and <code class="docutils literal notranslate"><span class="pre">brain_wt</span></code> by taking their natural logarithm (<code class="docutils literal notranslate"><span class="pre">np.log()</span></code>).</p></li>
<li><p>Fit a linear regression model to the log-transformed data.</p></li>
<li><p>Print the equation of your model.</p></li>
<li><p>Plot the log-transformed data as a scatter plot and overlay your regression line.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Data for Exercise 1</span>
<span class="n">body_wt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">3.385</span><span class="p">,</span> <span class="mf">0.48</span><span class="p">,</span> <span class="mf">1.35</span><span class="p">,</span> <span class="mf">465.0</span><span class="p">,</span> <span class="mf">36.33</span><span class="p">,</span> <span class="mf">27.66</span><span class="p">,</span> <span class="mf">1.04</span><span class="p">,</span> <span class="mf">4.235</span><span class="p">,</span> <span class="mf">10.55</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">600.0</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">,</span> <span class="mf">6.8</span><span class="p">,</span> <span class="mf">35.0</span><span class="p">,</span> <span class="mf">3.92</span><span class="p">,</span> <span class="mf">572.0</span><span class="p">,</span> <span class="mf">180.0</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">1.92</span><span class="p">,</span> <span class="mf">119.5</span><span class="p">,</span> <span class="mf">85.0</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">14.83</span><span class="p">,</span> <span class="mf">192.0</span><span class="p">])</span>
<span class="n">brain_wt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">44.5</span><span class="p">,</span> <span class="mf">15.5</span><span class="p">,</span> <span class="mf">8.1</span><span class="p">,</span> <span class="mf">423.0</span><span class="p">,</span> <span class="mf">119.5</span><span class="p">,</span> <span class="mf">115.0</span><span class="p">,</span> <span class="mf">5.5</span><span class="p">,</span> <span class="mf">25.6</span><span class="p">,</span> <span class="mf">73.5</span><span class="p">,</span> <span class="mf">2.4</span><span class="p">,</span> <span class="mf">6.6</span><span class="p">,</span> <span class="mf">812.0</span><span class="p">,</span> <span class="mf">10.8</span><span class="p">,</span> <span class="mf">12.3</span><span class="p">,</span> <span class="mf">37.0</span><span class="p">,</span> <span class="mf">57.0</span><span class="p">,</span> <span class="mf">17.5</span><span class="p">,</span> <span class="mf">655.0</span><span class="p">,</span> <span class="mf">157.0</span><span class="p">,</span> <span class="mf">12.1</span><span class="p">,</span> <span class="mf">11.4</span><span class="p">,</span> <span class="mf">75.0</span><span class="p">,</span> <span class="mf">62.0</span><span class="p">,</span> <span class="mf">4.7</span><span class="p">,</span> <span class="mf">48.0</span><span class="p">,</span> <span class="mf">180.0</span><span class="p">])</span>

<span class="c1"># 1. (Data is already loaded)</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="conclusion-what-s-next">
<h2><span class="section-number">8.7. </span>Conclusion &amp; What’s Next?<a class="headerlink" href="#conclusion-what-s-next" title="Link to this heading">#</a></h2>
<p><strong>Key Takeaways:</strong></p>
<ul class="simple">
<li><p>Supervised learning uses <strong>labeled data</strong> (X, y) to learn a predictive function.</p></li>
<li><p><strong>Regression</strong> predicts continuous values, while <strong>Classification</strong> predicts discrete categories.</p></li>
<li><p><strong>Linear Regression</strong> finds the best-fit line by minimizing a <strong>cost function</strong> (like MSE).</p></li>
<li><p><strong>Gradient Descent</strong> is the optimization algorithm used to find the model parameters that minimize the cost.</p></li>
<li><p>Libraries like <strong>Scikit-Learn</strong> make it incredibly easy to implement these powerful models.</p></li>
</ul>
<p><strong>What’s Next?</strong></p>
<ul class="simple">
<li><p>What if our data isn’t linear? We can use <strong>Polynomial Regression</strong>.</p></li>
<li><p>How do we handle classification problems? We’ll use models like <strong>Logistic Regression</strong> and <strong>Support Vector Machines</strong>.</p></li>
<li><p>What happens when we have many features? We need to be careful about <strong>overfitting</strong> and use techniques like <strong>regularization</strong>.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./lectures/04-LinearRegression"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../03-PCA/PCA.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">7. </span>Principal Component Analysis (PCA)</p>
      </div>
    </a>
    <a class="right-next"
       href="../07-IntroNeuralNetworks/NeuralNetworks-BasicConcepts.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">9. </span>What is a Neural Network?</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#review-what-is-machine-learning">8.1. Review: What is Machine Learning?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-learning">8.2. Supervised Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-regression-predicting-a-continuous-value">8.2.1. A. Regression: Predicting a Continuous Value</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-classification-predicting-a-discrete-category">8.2.2. B. Classification: Predicting a Discrete Category</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression">8.3. Linear Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-goal">8.3.1. The Goal</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-find-the-best-line">8.4. How Do We Find the “Best” Line?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization-with-gradient-descent">8.4.1. Optimization with Gradient Descent</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-physics-example-hooke-s-law">8.5. A Physics Example - Hooke’s Law</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-generation">8.5.1. Data Generation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-using-sklearn">8.5.2. Linear regression using <code class="docutils literal notranslate"><span class="pre">sklearn</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practice-exercises">8.6. Practice Exercises</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tensorflow-pytorch">8.6.1. Tensorflow/pytorch</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#biology-brain-vs-body-weight">8.6.2. Biology - Brain vs. Body Weight</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-what-s-next">8.7. Conclusion &amp; What’s Next?</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Veronica Arias, Carlos Viviescas, William Oquendo
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>